{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e44d427",
   "metadata": {},
   "source": [
    "**EE5180: Introduction to Machine Learning** \\\n",
    "**Submitted by:** Akash Sharma (EE21S056)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d3ea8",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "   You are a drug manufacturer and you want to study whether your drug, namely drug A, leads to a higher rate of recovery than drug B. What are the input samples/feature vectors you will use, the loss function, hypothesis classes and the output labels. Justify your answers.\n",
    "\n",
    "   How many samples of feature vectors will you require to obtain a PAC solution? Propose a learning algorithm and evaluate its performance using some toy data set.\n",
    "\n",
    "   Now, let us bring a small twist to the problem. Instead of wanting to study whether your drug is better, you want to show using your algorithm that your drug is indeed better. What is the difference between the above and the current scenario? How will you use the data set you had for the previous problem and obtain a PAC solution which favors drug A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cc0f24",
   "metadata": {},
   "source": [
    "# Solution\n",
    "\n",
    "   Before deciding the particulars of the learning algorithm, it is necessary to fix the design of the clinical trial for comparing the two drugs A and B, which are *assumed* to be used as treatment for a fictitious disease. Here, a fictitious disease is chosen since the feature selection for the input samples is randomized and depends on some of my prior knowledge (experience), for example *it is quite likely that a person's response to a drug depends on their age*; it also depends on the design of the trial which takes into account the outcomes that the experimenter is interested in. For this particular problem, we are interested in the **rate of recovery** of the patient population as function of the drug used out of the two given choices. \n",
    "   \n",
    "   In case an existing disease was chosen, it would require disease specific knowledge about the factors affecting the treatment of such a disease and the feature vector would have to be selected appropriately. Another reason a fictitious disease has been chosen is to circumvent the problem of acquiring disease specific knowledge, though in the real world applications this is not an option.\n",
    "\n",
    "## Clinical Trial Setup\n",
    "\n",
    "The general outcome of a drug trial is the measures of safety and efficacy for that particular drug in a highly controlled environment [1]. It is quite common to find the effects of a single drug on the selected patient population which is divided into two groups -- treatment group which is subjected to the drug and a control group which is subjected to a placebo drug. However, comparing the effects of two different drugs to find which one is better needs a different method, it is suggested that a head-to-head trial [2] is done in such cases. \n",
    "\n",
    "In a head-to-head trial or a randomized controlled trial [3] , from the total selected patients, two groups are chosen which are similar to each other in distribution of types of patients based on various factors that clinicians deem fit to be the indicators of similarity. Each group is then matched with either of the two drugs that are being compared and the results are noted, these results then would be indicative of the efficacy of each drug on a certain patient population because they were divided in such a way that no bias would be induced from the differences in the two groups since there are no differences (ideally).\n",
    "\n",
    "One **problem** I faced while trying to design the trial was lack of public datasets which followed the head-to-head trial approach. Instead, I tried to relax the conditions required for the methods mentioned above and went with a naive direct approach for comparison of the two drugs [4], in this method the similarities between the two groups is not considered and a direct comparison of the effects of each drug is made, this leads to comparison errors caused by difference in distribution of types of patients in each group, however here simplicity of design takes precedence over consequential errors. A few assumptions have to made before we move forward -\n",
    "\n",
    "- **Drug A** is still in trial phases and has not been tested on many patients.\n",
    "\n",
    "- **Drug B** has been in the market for a long time and has both trial data and real world data available reflecting its effect on a variety of patients. Therefore, recovery rate of patients is known and has high accuracy with high confidence because of the sheer number of test and observational data samples.  \n",
    "\n",
    "- The disease can be treated (if the drug works) in a relatively smaller time frame, for example 14 days at maximum. This means after administering a drug to a patient, the effects can be noted within 14 days. Particularly for the trial study here, the effect of interest is if the patient recovered from the disease or not i.e., if all the symptoms have been alleviated and patient has returned to state of normal body function. \n",
    "\n",
    "### Need of learning algorithms\n",
    "\n",
    "Typically, there is *no need of machine learning algorithms* for finding out the efficacy and safety measures of a drug since the goal of the drug trial is the same and would anyway be known once the study is concluded. However, it is well known that drug trial studies could take multiple years [5] due to factors such as induction of potential candidates for the study, the time required for multiple experiments/tests etc. In such cases, how is it possible to find out comparative performance of a drug on a larger patient population given a much smaller subset of such a population? Here, learning algorithms could be used for such predictions i.e., using a smaller subset of patient outcomes, we can predict the outcome for a larger subset with some arbitrary degree of confidence and accuracy. \n",
    "\n",
    "### Trial Design\n",
    "\n",
    "The goal of this trial is to acquire enough data to find out *if drug A **leads** to higher recovery rate than drug B*. For each patient, the following measurements are recorded after a few tests -\n",
    "\n",
    "1. Age (`Age`) - Age of each patient is recorded. It ranges from `15` to `74`. \n",
    "2. Sex (`Sex`) - Recorded as Male (`M`) or Female (`F`).\n",
    "3. Blood Pressure (`BP`) - Recorded as `HIGH`, `LOW` and `NORMAL`.\n",
    "4. Cholesterol (`Cholesterol`) - Recorded as `HIGH` and `NORMAL`.\n",
    "5. Dominant biomarker (`dom_marker`) - Another biomarker is chosen which dominates the condition of the patient and their reaction to the drug. \n",
    "\n",
    "All of the above are *assumed* to be features of the patient's profile which affect the state of recovery of the patient once the drug is administered. These features will be used as elements of the *feature vectors* or *input samples* for the learning algorithm. \n",
    "\n",
    "After taking the above measurements, the patient is administered with drug A and the effect is recorded in the dataset under the column `recovery` with choices as `YES` and `NO` where the former means that the patient has recovered from the disease and is healthy now, the latter means that patient's body has resisted treatment and is not healthy. One question still remains, how many patients are needed so that eventually the learning algorithm we choose can successfully predict what we want it to predict? For now, we will just *assume* that we need an arbitrary number of patients which are generally characteristic of such a study, say about 200. It should be noted that this number is *arbitrary* and could have been something else as well. The reason for selecting an arbitrary number will be explained in the upcoming sections where we discuss hypothesis classes. \n",
    "\n",
    "### Dataset Synthesis\n",
    "\n",
    "Since there is no provision for performing the above study and no other matching study was found, one way to get a dataset is to synthesize it. Here I use some seed data that I found on Kaggle [6]. After performing some manipulation so that it fits our application, it looks like as shown below. The programming language used in this report is `Python 3.8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be651051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex      BP Cholesterol  dom_marker\n",
      "0   23   F    HIGH        HIGH      25.355\n",
      "1   47   M     LOW        HIGH      13.093\n",
      "2   47   M     LOW        HIGH      10.114\n",
      "3   28   F  NORMAL        HIGH       7.798\n",
      "4   61   F     LOW        HIGH      18.043\n",
      "\n",
      "The dimensions of the dataset are (200, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import warnings #comment this out in case warnings need to be seen\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "patient = pd.read_csv(\"patient.csv\")\n",
    "print(patient.head()) #show first five entries in the dataset\n",
    "print(\"\") #empty space for visibility\n",
    "print(\"The dimensions of the dataset are\",patient.shape) #print dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe31e9b",
   "metadata": {},
   "source": [
    "It can be seen that there are 200 patients for whom the relevant data has been recorded. However, the `recovery` column is not shown. I will add that column later on after synthesizing more patients using a distribution representative of the original dataset which is shown above. The reason we need more patients is because we do not have a dataset for drug B. The strategy from here onwards is to synthesize more patient information from the seed dataset `patient` and then **randomly** label each patient with the `recovery` labels, `YES` or `NO` for drug B, this will give us a larger dataset with information about the recovery rate of drug B (which is in our control). After doing that, we will again randomly label the seed dataset `patient` with the `recovery` labels for drug A. Finally, we will have two datasets, each for drug A and B. \n",
    "\n",
    "For patient data synthesis, a `Python` package named Synthetic Data Vault or `SDV` is used [7]. Use `pip install sdv` to install the package on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c903ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_num</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>dom_marker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_num  Age Sex      BP Cholesterol  dom_marker\n",
       "0           0   23   F    HIGH        HIGH      25.355\n",
       "1           1   47   M     LOW        HIGH      13.093\n",
       "2           2   47   M     LOW        HIGH      10.114\n",
       "3           3   28   F  NORMAL        HIGH       7.798\n",
       "4           4   61   F     LOW        HIGH      18.043"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding serial_num column for creating unique identifier for a patient\n",
    "patient.insert(loc=0, column='serial_num', value=np.arange(len(patient)))\n",
    "patient.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0afa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   serial_num  Age Sex      BP Cholesterol  dom_marker\n",
      "0           0   46   F  NORMAL        HIGH      17.986\n",
      "1           1   35   M  NORMAL        HIGH      12.031\n",
      "2           2   18   F    HIGH      NORMAL      20.377\n",
      "3           3   39   F    HIGH        HIGH      12.298\n",
      "4           4   68   M  NORMAL        HIGH       7.864\n",
      "\n",
      "The dimensions of extend_patient are (2000, 6)\n"
     ]
    }
   ],
   "source": [
    "from sdv.tabular import GaussianCopula\n",
    "'''\n",
    "GaussianCopula is one of the models used for fitting the seed dataset, other \n",
    "options available are CTGan, CopulaGAN etc. GaussianCopula model will look \n",
    "for joint marginal distribution of multiple features/columns in the dataset \n",
    "and synthesize a new dataset with statistically similar distribution.\n",
    "''' \n",
    "# use serial number as unique identifier\n",
    "synth_model = GaussianCopula(primary_key='serial_num') \n",
    "synth_model.fit(patient) #fit the synthesis model\n",
    "\n",
    "extend_patient = synth_model.sample(2000) # create dataset with 2000 patients\n",
    "print(extend_patient.head())\n",
    "print(\"\")\n",
    "print(\"The dimensions of extend_patient are\",extend_patient.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119e01e4",
   "metadata": {},
   "source": [
    "Now, we have a dataset with 2000 patients which is *statistically representative* of the seed dataset.\n",
    "\n",
    "To evaluate how well the synthesized dataset represents the original dataset, we can use various metrics. Here, I have used *Chi-Squared Test* and *Kolmogorov-Smirnov Test*. The score ranges from `0` to `1` and higher the score,\n",
    "better the synthesis. As can be seen from `CSTest`, the synthesis is acceptable but for `KSTest` it is comparatively lower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54402323",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>name</th>\n",
       "      <th>raw_score</th>\n",
       "      <th>normalized_score</th>\n",
       "      <th>min_value</th>\n",
       "      <th>max_value</th>\n",
       "      <th>goal</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSTest</td>\n",
       "      <td>Chi-Squared</td>\n",
       "      <td>0.992125</td>\n",
       "      <td>0.992125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAXIMIZE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KSTest</td>\n",
       "      <td>Inverted Kolmogorov-Smirnov D statistic</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>0.669500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MAXIMIZE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric                                     name  raw_score  \\\n",
       "0  CSTest                              Chi-Squared   0.992125   \n",
       "1  KSTest  Inverted Kolmogorov-Smirnov D statistic   0.669500   \n",
       "\n",
       "   normalized_score  min_value  max_value      goal error  \n",
       "0          0.992125        0.0        1.0  MAXIMIZE  None  \n",
       "1          0.669500        0.0        1.0  MAXIMIZE  None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sdv.evaluation import evaluate\n",
    "evaluate(extend_patient, patient, metrics=['CSTest', 'KSTest'], aggregate = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18416ac",
   "metadata": {},
   "source": [
    "Now, let us create `drugA` dataset with 200 patients and corresponding `recovery` labels `YES` and `NO` as described earlier. Also, we do the same for `drugB` with 2000 patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e92410fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_num</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>dom_marker</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>17.986</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12.031</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>20.377</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>12.298</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>M</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.864</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_num  Age Sex      BP Cholesterol  dom_marker recovery\n",
       "0           0   46   F  NORMAL        HIGH      17.986       NO\n",
       "1           1   35   M  NORMAL        HIGH      12.031      YES\n",
       "2           2   18   F    HIGH      NORMAL      20.377      YES\n",
       "3           3   39   F    HIGH        HIGH      12.298      YES\n",
       "4           4   68   M  NORMAL        HIGH       7.864      YES"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Creating drugB dataset.The probabilities for 'YES' defines the \n",
    "likeliness of the drug to work on the patient. For drug B, this \n",
    "likeliness is 0.7 irrespective of other columns for a specific patient.\n",
    "'''\n",
    "\n",
    "recovery_B = np.random.choice(['YES', 'NO'], size = 2000, p = [.7, .3])\n",
    "extend_patient['recovery'] = recovery_B.tolist()\n",
    "drugB = extend_patient\n",
    "drugB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64a5d8db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>serial_num</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>dom_marker</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   serial_num  Age Sex      BP Cholesterol  dom_marker recovery\n",
       "0           0   23   F    HIGH        HIGH      25.355      YES\n",
       "1           1   47   M     LOW        HIGH      13.093      YES\n",
       "2           2   47   M     LOW        HIGH      10.114      YES\n",
       "3           3   28   F  NORMAL        HIGH       7.798       NO\n",
       "4           4   61   F     LOW        HIGH      18.043       NO"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Creating drugA dataset.The probabilities for 'YES' defines the \n",
    "likeliness of the drug to work on the patient. For drug A, this \n",
    "likeliness is 0.8 irrespective of other columns for a specific patient.\n",
    "'''\n",
    "\n",
    "recovery_A = np.random.choice(['YES', 'NO'], size = 200, p = [.8, .2])\n",
    "patient['recovery'] = recovery_A.tolist()\n",
    "drugA = patient\n",
    "drugA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce414d5",
   "metadata": {},
   "source": [
    "Finally, we have our datasets $-$\n",
    "\n",
    "\n",
    "- `drugA` dataset: This is the data acquired from clinical trial held by the drug manufacturer as described earlier in the trial design section. Number of patients is 200 and each patient is labeled for if they recovered from the disease when administered with drug A.\n",
    "\n",
    "\n",
    "- `drugB` dataset: This is taken as the old data from clinical trials held for drug B. Number of patients is 2000 and each patient is labeled if they recovered from the disease when administered with drug B. \n",
    "\n",
    "### Comments on Synthetic data\n",
    "\n",
    "1. It is imperative that since the data is synthetic and the disease and drugs work exist in an imaginary situation, the inferences from this data might not make sense in the real world. For example, a patient with *relatively healthier* feature set can be inferred as non-recoverable from the disease which in real life would be highly unlikely given that there are no other factors affecting the patient's recovery. In such cases, the inferences made by the learning algorithm can turn out to be gibberish (in the real world but not in the imaginary world where the problem is set) not due to the model's incapability to learn but due to the dataset itself. \n",
    "\n",
    "2. Another thing to keep in mind is that the dataset could turn out to be *non-informative* or it could also be *non-separable* i.e., when all feature vectors are plotted in an `n`-dimensional feature space where `n` is the number of features, the feature vectors could possibly show no patterns or clusters in which case, classification would not be possible for the given sample size.\n",
    "\n",
    "3. There is lack of prior knowledge about the data since the setting is imaginary, in such a case, some exploratory data analysis would be needed to decide the candidate hypothesis classes.\n",
    "\n",
    "4. An **significant** improvement on assignment of `recovery` labels would have been to use a clustering model to find clusters in the feature space and use those clusters for assignment. However, due to time constraint for this exam, I have avoided that.\n",
    "\n",
    "Considering these warnings, it is possible that any model we choose may not be able to learn very well but in case, the conditions in the second comment do not come to pass, a model could learn well given the data it has been presented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c731110",
   "metadata": {},
   "source": [
    "## The Learning Model\n",
    "\n",
    "We set this problem as a **classification** problem in a **supervised** setting. Given a patient, a model would have to predict if they will recover or not when given drug A. Firstly, using the `drugA` dataset, we will train our model and check its accuracy using train-test data split. Secondly, we will calculate the recovery rate using the model for prediction on a dataset which has been labeled for drug B as well (`drugB` dataset). Finally, we will compare the recovery rate for the drugs.\n",
    "\n",
    "In the following subsections, we define our learning problem in detail and justify our choices for each of the components involved in the learning setup. \n",
    "\n",
    "\n",
    "### Feature Vectors\n",
    "\n",
    "Before even defining the learning model in this section, I created datasets with particular feature sets or columns in mind. The feature vectors or the input samples are just the patient's data `(Age, Sex, BP, Cholesterol, dom_marker)` as shown in the datasets. Formally for $x \\in \\mathcal{X}$, $x$ takes the form\n",
    "\n",
    "$$x^k = \\big(x_{1}^{k}, x_{2}^{k},...,x_{m}^{k}\\big)$$\n",
    "\n",
    "where $k = |\\mathcal{X}|$ and $m$ is number of features. Here, $k$ will be equal to however many samples we choose to train our model with and $m = 5$ as can seen be from the dataset.\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "Since this problem is a *binary classification problem*, the simplest choice would be the **0-1 loss**[8] where the loss function outputs `0` if the predicted value is equal to the true value and `1`, otherwise.\n",
    "\n",
    "### Hypothesis Classes & PAC Learnability\n",
    "\n",
    "For this particular problem of drug comparison, there is little prior knowledge that can be used for *inducing a bias*, therefore choosing hypothesis classes with the help of domain knowledge is not possible. It is possible to reduce the number of hypothesis candidates by visualizing the data as well, however it would not be possible for feature vectors with features greater than 3 since visualization would not be possible in those cases. Earlier in section 2.1.1, while discussing the number of samples taken in the trial study, I decided to take an arbitrary number because for learning a PAC solution we would require the **cardinality of the hypothesis class** which in fact has not been chosen due to the aforementioned reasons. Therefore, *no comment on the sample complexity could be made*. As we will see in the next section, when we choose our learner, we can easily change hypothesis classes as well. \n",
    "\n",
    "Thus, instead of fixing the hypothesis class $\\mathcal{H}$ ahead of time, we can go for different models and use validation to find the best model as discussed in Chapter 7 [8]. \n",
    "\n",
    "\n",
    "### Output Labels\n",
    "\n",
    "As mentioned earlier, this is a binary classification problem and the classification labels are `YES` when the patient recovers from the disease within 14 days upon taking drug A and `NO` when the patient does not recover. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d7b240",
   "metadata": {},
   "source": [
    "## Learning Algorithms & their Performance\n",
    "\n",
    "For a classification task, many learning algorithms are present [9] such as logistic regression, naive Bayes, Support Vector Machines (SVMs), Decision Trees, Random Forest etc. For this particular task, I choose to use SVMs due to their *robustness* and *ability to deal with highly multidimensional feature spaces* [8]. One other reason is that if SVM is chosen to be the learner for our problem, it is easier to use different hypothesis classes by simply changing the **kernel** function which is quite easy to implement as well. Before, using these learning algorithms, it is important to make the data ready for input. \n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "Let us first remove features which have no significance for learning the classification task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1fb5fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>dom_marker</th>\n",
       "      <th>recovery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>25.355</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>13.093</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>10.114</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>F</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>7.798</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>F</td>\n",
       "      <td>LOW</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>18.043</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex      BP Cholesterol  dom_marker recovery\n",
       "0   23   F    HIGH        HIGH      25.355      YES\n",
       "1   47   M     LOW        HIGH      13.093      YES\n",
       "2   47   M     LOW        HIGH      10.114      YES\n",
       "3   28   F  NORMAL        HIGH       7.798       NO\n",
       "4   61   F     LOW        HIGH      18.043       NO"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing serial_num since it has no significance for classification\n",
    "drugA = drugA.drop(['serial_num'], axis = 1)\n",
    "drugA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3d6d97",
   "metadata": {},
   "source": [
    "Let us also check out the data type of each feature in the dataset. Below, it can be seen that the features `Sex`, `BP`, `Cholesterol` and `recovery` are categorical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e5740fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age              int64\n",
      "Sex             object\n",
      "BP              object\n",
      "Cholesterol     object\n",
      "dom_marker     float64\n",
      "recovery        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(drugA.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c59bf",
   "metadata": {},
   "source": [
    "For dealing with categorical variables, we can use encoding [11] according to the type of categorical feature. `recovery` will be our target variable, therefore it needs to be encoded as well. For `NO`, we can encode it as `0` and for `YES`, encode it as `1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d3e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugA.loc[drugA[\"recovery\"] == \"YES\", \"recovery\"] = 1\n",
    "drugA.loc[drugA[\"recovery\"] == \"NO\", \"recovery\"] = 0\n",
    "\n",
    "#change recovery variable to numeric to avoid one-hot encoding\n",
    "drugA['recovery'] = pd.to_numeric(drugA['recovery'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1469b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>dom_marker</th>\n",
       "      <th>recovery</th>\n",
       "      <th>Sex_F</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>BP_HIGH</th>\n",
       "      <th>BP_LOW</th>\n",
       "      <th>BP_NORMAL</th>\n",
       "      <th>Cholesterol_HIGH</th>\n",
       "      <th>Cholesterol_NORMAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>25.355</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>13.093</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>10.114</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61</td>\n",
       "      <td>18.043</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  dom_marker  recovery  Sex_F  Sex_M  BP_HIGH  BP_LOW  BP_NORMAL  \\\n",
       "0   23      25.355         1      1      0        1       0          0   \n",
       "1   47      13.093         1      0      1        0       1          0   \n",
       "2   47      10.114         1      0      1        0       1          0   \n",
       "3   28       7.798         0      1      0        0       0          1   \n",
       "4   61      18.043         0      1      0        0       1          0   \n",
       "\n",
       "   Cholesterol_HIGH  Cholesterol_NORMAL  \n",
       "0                 1                   0  \n",
       "1                 1                   0  \n",
       "2                 1                   0  \n",
       "3                 1                   0  \n",
       "4                 1                   0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using get_dummies method to one-hot encode all categorical variables\n",
    "ohe_drugA = pd.get_dummies(drugA)\n",
    "ohe_drugA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebacfd3",
   "metadata": {},
   "source": [
    "Let us also check the distribution of target labels to see if we have a balanced or an imbalanced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8ad3227",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.81\n",
       "0    0.19\n",
       "Name: recovery, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_drugA['recovery'].value_counts()/np.float(len(ohe_drugA))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b03eaf",
   "metadata": {},
   "source": [
    "### Training and testing algorithms\n",
    "\n",
    "First, we create a input sample dataset `X` and `y` is the target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60ee48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop target variable\n",
    "X = ohe_drugA.drop(['recovery'], axis = 1)\n",
    "y = ohe_drugA['recovery'] #create target dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c45c6",
   "metadata": {},
   "source": [
    "Now, we do a train-test split using `scikit-learn` functions. From here on, the code has been majorly reused from [12]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1aa8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((160, 9), (40, 9))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba2a82",
   "metadata": {},
   "source": [
    "**Feature scaling** [13] to standardize independent features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41efc470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "cols = X_train.columns\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbddf23",
   "metadata": {},
   "source": [
    "#### Hypothesis Class I : Radial Basis Functions\n",
    "\n",
    "Here, the kernel function used with SVM is radial basis function (rbf), changing the parameter `C` which handles outliers results in different hypothesis in this class. Here, we consider three hypothesis with `C` = 1, 100 and 1000. The code cell below implements `C` = 1.0 which is the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "412c019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.8250\n"
     ]
    }
   ],
   "source": [
    "# import SVC classifier\n",
    "from sklearn.svm import SVC\n",
    "# import metrics to compute loss and accuracy\n",
    "from sklearn.metrics import zero_one_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "# instantiate classifier with default hyperparameters\n",
    "svc=SVC() \n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46549d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=100.0 : 0.8000\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=100\n",
    "svc=SVC(C=100.0) \n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23022739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with rbf kernel and C=1000.0 : 0.8000\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with rbf kernel and C=1000\n",
    "svc=SVC(C=1000.0) \n",
    "# fit classifier to training set\n",
    "svc.fit(X_train,y_train)\n",
    "# make predictions on test set\n",
    "y_pred=svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377da92",
   "metadata": {},
   "source": [
    "#### Hypothesis Class II : Linear Functions\n",
    "\n",
    "Here, in this class, the kernel function is limited to linear functions. As before, the value of `C` is changed and three possible hypothesis are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1afedcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1.0 : 0.8250\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1.0\n",
    "linear_svc=SVC(kernel='linear', C=1.0) \n",
    "# fit classifier to training set\n",
    "linear_svc.fit(X_train,y_train)\n",
    "# make predictions on test set\n",
    "y_pred_test=linear_svc.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4c8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=100.0 : 0.8250\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=100.0\n",
    "linear_svc100=SVC(kernel='linear', C=100.0) \n",
    "# fit classifier to training set\n",
    "linear_svc100.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred=linear_svc100.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8604a5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with linear kernel and C=1000.0 : 0.8250\n"
     ]
    }
   ],
   "source": [
    "# instantiate classifier with linear kernel and C=1000.0\n",
    "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
    "# fit classifier to training set\n",
    "linear_svc1000.fit(X_train, y_train)\n",
    "# make predictions on test set\n",
    "y_pred=linear_svc1000.predict(X_test)\n",
    "# compute and print accuracy score\n",
    "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(1-zero_one_loss(y_test, y_pred_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d642d56",
   "metadata": {},
   "source": [
    "From the accuracy score, it can be seen that **Linear SVM** is a better hypothesis class since all the hypothesis have lesser loss score as compared to **Radial Basis Function SVM**. However, this accuracy can be improved if we had better prior knowledge to narrow down the hypotheses. Now, let us select linear SVM model for checking underfitting or overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26949935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction on training dataset\n",
    "y_pred_train = linear_svc.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25005316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training-set accuracy score: 0.8063\n"
     ]
    }
   ],
   "source": [
    "# checking for overfitting\n",
    "print('Training-set accuracy score: {0:0.4f}'. format(1-zero_one_loss(y_train, y_pred_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8691f8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.8063\n",
      "Test set score: 0.8250\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
    "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1349c",
   "metadata": {},
   "source": [
    "From above, it is obvious that our model performs averagely because of the hypothesis classes that we selected. Thus, the guarantees that this model provides for its predictions is not strong. To get stronger guarantees i.e., lesser values of $\\epsilon$ and $\\delta$, we need more data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f2d7c",
   "metadata": {},
   "source": [
    "## Difference between finding which is better versus being indeed better?\n",
    "\n",
    "Now that we have selected our hypothesis (however inaccurate it may be), we can find whether drug A has better recovery rate than drug B. However, when we try to do that, we do not have particulary a high confidence with the predicted recovery rate for drug A. In that case, we cannot be sure if our drug is *indeed* better i.e., in terms of PAC solution, the probability of being accurate is not very high. To say one drug is *indeed* better than the other, we would need to provide the prediction accurately with probability 1 but for that sample complexity would have to very high (infinite) since sample complexity is inversely proportional to confidence parameter $\\delta$.\n",
    "\n",
    "There is another way to comment on if one drug is better than the other or not and that is through finding the **effectiveness** of the drug [1] rather than the **efficacy** which means we need prove using a learning algorithm that the drug is more effective (it performs well in the real world not only in a controlled lab environment). To do that, a learning algorithm would need to find the relationship between efficacy and effectiveness. This can be done through a thorough study of relationship between surrogate-based outcomes and patient-oriented outcomes [1].\n",
    "\n",
    "For a PAC solution to favor drug A, the dataset should also reflect superiority of drug A otherwise, our model will never favor A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f65dea",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Drug comparison requires a lot of domain-specific study and trials have to be designed very carefully. A machine learning algorithm without an inductive bias will not be good learner since it will have to search in a very large hypothesis space for which large amount of data is required which is not alway available as in cases of new drugs being introduced in the market or in trial phases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea1597b",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] [Drug Efficacy and Safety](https://www.merckmanuals.com/professional/clinical-pharmacology/concepts-in-pharmacotherapy/drug-efficacy-and-safety)\n",
    "\n",
    "[2] Eduara Vieta, Nuria Cruz,Head to head comparisons as an alternative to placebo-controlled trials, European Neuropsychopharmacology, Volume 22, Issue 11, 2012, Pages 800-803, ISSN 0924-977X, [DOI](https://doi.org/10.1016/j.euroneuro.2011.11.011)\n",
    "\n",
    "[3] [Randomised Trials](https://www.cancerresearchuk.org/about-cancer/find-a-clinical-trial/what-clinical-trials-are/randomised-trials)\n",
    "\n",
    "[4] Kim H, Gurrin L, Ademi Z, Liew D. Overview of methods for comparing the efficacies of drugs in the absence of head-to-head clinical trial data. Br J Clin Pharmacol. 2014;77(1):116-121,[DOI](https://doi.org/10.1111/bcp.12150)\n",
    "\n",
    "[5] [Clinical Trial Results](https://www.cancerresearchuk.org/about-cancer/find-a-clinical-trial/clinical-trial-results)\n",
    "\n",
    "[6] https://www.kaggle.com/datasets/pablomgomez21/drugs-a-b-c-x-y-for-decision-trees\n",
    "\n",
    "[7] [SDV Documentation](https://sdv.dev/SDV/user_guides/single_table/index.html)\n",
    "\n",
    "[8] Shai Shalev-Shwartz and Shai Ben-David. 2014. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, USA.\n",
    "\n",
    "[9] [Machine Learning Algorithms for Classification](https://towardsdatascience.com/top-machine-learning-algorithms-for-classification-2197870ff501)\n",
    "\n",
    "[10] Lecture notes, EE5180 (Spring 2022), IIT Madras\n",
    "\n",
    "[11] [One Hot Encoding & Label Encoding](https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/)\n",
    "\n",
    "[12] [SVM Classifier Tutorial](https://www.kaggle.com/code/prashant111/svm-classifier-tutorial/notebook)\n",
    "\n",
    "[13] [Feature Scaling](https://www.geeksforgeeks.org/ml-feature-scaling-part-2/#:~:text=Feature%20Scaling%20is%20a%20technique,magnitudes%20or%20values%20or%20units.)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
